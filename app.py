import streamlit as st
import pandas as pd
import numpy as np
import requests
from datetime import datetime, timedelta
import time
import joblib
import os
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from imblearn.combine import SMOTEENN
import warnings
warnings.filterwarnings('ignore')

# Tentar importar modelos avan√ßados
try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="‚öΩ HT Goals AI Engine - MAX PERFORMANCE",
    page_icon="üéØ",
    layout="wide"
)

# Inicializar session state
if 'trained_model' not in st.session_state:
    st.session_state.trained_model = None
if 'model_trained' not in st.session_state:
    st.session_state.model_trained = False

# Configura√ß√£o da API
try:
    API_KEY = st.secrets["API_KEY"]
except:
    API_KEY = "474f15de5b22951077ccb71b8d75b95c"

API_BASE_URL = "https://v3.football.api-sports.io"
MODEL_DIR = "models"

try:
    if not os.path.exists(MODEL_DIR):
        os.makedirs(MODEL_DIR)
except Exception:
    MODEL_DIR = "/tmp/models"
    if not os.path.exists(MODEL_DIR):
        os.makedirs(MODEL_DIR)

def get_api_headers():
    return {'x-apisports-key': API_KEY}

def test_api_connection():
    try:
        headers = get_api_headers()
        response = requests.get(f'{API_BASE_URL}/status', headers=headers, timeout=10)
        return response.status_code == 200, "Conex√£o OK" if response.status_code == 200 else f"Status: {response.status_code}"
    except Exception as e:
        return False, f"Erro: {str(e)}"

def get_fixtures_with_retry(date_str, max_retries=3):
    headers = get_api_headers()
    for attempt in range(max_retries):
        try:
            response = requests.get(
                f'{API_BASE_URL}/fixtures',
                headers=headers,
                params={'date': date_str},
                timeout=30
            )
            if response.status_code == 200:
                data = response.json()
                if 'errors' in data and data['errors']:
                    return []
                return data.get('response', [])
            else:
                if attempt < max_retries - 1:
                    time.sleep(2 ** attempt)
        except Exception:
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
    return []

@st.cache_data(ttl=3600, show_spinner=False)
def get_fixtures_cached(date_str):
    return get_fixtures_with_retry(date_str)

def load_historical_data():
    data_files = [
        "data/historical_matches.parquet",
        "data/historical_matches.csv", 
        "historical_matches.parquet",
        "historical_matches.csv",
        "data/historical_matches_complete.parquet",
        "data/historical_matches_cache.parquet"
    ]
    
    for file_path in data_files:
        if os.path.exists(file_path):
            try:
                if file_path.endswith('.parquet'):
                    df = pd.read_parquet(file_path)
                else:
                    df = pd.read_csv(file_path)
                
                if 'ht_home' in df.columns and 'ht_away' in df.columns:
                    df['over_05'] = (df['ht_home'] + df['ht_away']) > 0
                return df, f"‚úÖ {len(df)} jogos carregados do cache"
            except Exception:
                continue
    
    return None, "‚ùå Nenhum arquivo encontrado"

def collect_historical_data_smart(days=60, use_cached=True):
    if use_cached:
        df, message = load_historical_data()
        if df is not None:
            if days < 730:
                cutoff_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d')
                if 'date' in df.columns:
                    df_filtered = df[df['date'] >= cutoff_date].copy()
                    return df_filtered
            return df
    
    # Coleta otimizada da API
    st.warning("‚ö†Ô∏è Coletando dados da API...")
    sample_days = []
    
    # √öltimos 15 dias completos
    for i in range(15):
        sample_days.append(i + 1)
    # Amostragem inteligente para o resto
    for i in range(15, days, 3):
        sample_days.append(i + 1)
    
    all_data = []
    progress_bar = st.progress(0)
    
    for idx, day_offset in enumerate(sample_days):
        date = datetime.now() - timedelta(days=day_offset)
        date_str = date.strftime('%Y-%m-%d')
        
        fixtures = get_fixtures_cached(date_str)
        if fixtures:
            for match in fixtures:
                try:
                    if match['fixture']['status']['short'] == 'FT' and match.get('score', {}).get('halftime'):
                        match_data = extract_match_features(match)
                        if match_data:
                            all_data.append(match_data)
                except:
                    continue
        
        progress_bar.progress((idx + 1) / len(sample_days))
        if idx % 5 == 0:
            time.sleep(0.2)
    
    progress_bar.empty()
    
    # Salvar cache
    if len(all_data) > 50:
        try:
            df_new = pd.DataFrame(all_data)
            cache_file = "data/historical_matches_cache.parquet"
            os.makedirs("data", exist_ok=True)
            df_new.to_parquet(cache_file)
        except:
            pass
    
    return pd.DataFrame(all_data)

def extract_match_features(match):
    try:
        ht_home = match['score']['halftime']['home']
        ht_away = match['score']['halftime']['away']
        
        return {
            'date': match['fixture']['date'][:10],
            'timestamp': match['fixture']['timestamp'],
            'league_id': match['league']['id'],
            'league_name': match['league']['name'],
            'country': match['league']['country'],
            'home_team': match['teams']['home']['name'],
            'away_team': match['teams']['away']['name'],
            'home_team_id': match['teams']['home']['id'],
            'away_team_id': match['teams']['away']['id'],
            'ht_home_goals': ht_home,
            'ht_away_goals': ht_away,
            'ht_total_goals': ht_home + ht_away,
            'over_05': 1 if (ht_home + ht_away) > 0 else 0,
            'venue': match['fixture']['venue']['name'] if match['fixture']['venue'] else 'Unknown'
        }
    except Exception:
        return None

def prepare_ultra_ht_features(df):
    """
    üéØ FEATURES ULTRA-ESPEC√çFICAS PARA OVER 0.5 HT
    M√°xima performance focada 100% no primeiro tempo
    """
    
    if 'over_05' not in df.columns:
        if 'ht_home_goals' in df.columns and 'ht_away_goals' in df.columns:
            df['over_05'] = (df['ht_home_goals'] + df['ht_away_goals']) > 0
    
    if 'ht_total_goals' not in df.columns:
        if 'ht_home_goals' in df.columns and 'ht_away_goals' in df.columns:
            df['ht_total_goals'] = df['ht_home_goals'] + df['ht_away_goals']
    
    # Ordenar temporalmente
    if 'date' in df.columns:
        df = df.sort_values(['date', 'timestamp']).reset_index(drop=True)
    
    st.info("üéØ Preparando 40+ features ULTRA-ESPEC√çFICAS para Over 0.5 HT...")
    
    # Inicializar estat√≠sticas avan√ßadas dos times
    team_stats = {}
    unique_teams = pd.concat([df['home_team_id'], df['away_team_id']]).unique()
    
    for team_id in unique_teams:
        team_stats[team_id] = {
            # Estat√≠sticas b√°sicas
            'games': 0, 'over_05': 0, 'ht_goals_scored': 0, 'ht_goals_conceded': 0,
            'home_games': 0, 'home_over': 0, 'home_ht_goals': 0,
            'away_games': 0, 'away_over': 0, 'away_ht_goals': 0,
            
            # FEATURES HT ESPEC√çFICAS - Listas para c√°lculos avan√ßados
            'ht_goals_list': [], 'over_list': [], 'ht_clean_sheets': 0,
            
            # FEATURES HT ESPEC√çFICAS - Padr√µes temporais
            'early_goals_count': 0,  # Gols nos primeiros jogos da temporada
            'quick_start_games': 0,  # Jogos que marcaram cedo
            'ht_streaks': [],  # Sequ√™ncias de Over/Under
            'ht_dominance_games': 0,  # Jogos dominados no HT
            
            # FEATURES HT ESPEC√çFICAS - Efici√™ncia
            'ht_vs_ft_ratio': [],  # Rela√ß√£o gols HT vs FT
            'ht_conversion_rate': 0,  # Taxa convers√£o chances em gols HT
            'ht_pressure_games': 0,  # Jogos com press√£o inicial
            
            # FEATURES HT ESPEC√çFICAS - Contexto
            'big_game_ht_performance': 0,  # Performance HT em jogos grandes
            'venue_ht_factor': 0,  # Fator casa espec√≠fico HT
            'momentum_ht_shifts': []  # Mudan√ßas de momentum no HT
        }
    
    features = []
    total_rows = len(df)
    progress_bar = st.progress(0)
    progress_step = max(1, total_rows // 50)
    
    for idx, row in df.iterrows():
        if idx % progress_step == 0:
            progress_bar.progress(idx / total_rows)
        
        home_id = row['home_team_id']
        away_id = row['away_team_id']
        home_stats = team_stats[home_id]
        away_stats = team_stats[away_id]
        
        # ===== FEATURES B√ÅSICAS OTIMIZADAS =====
        home_ht_over_rate = home_stats['over_05'] / max(home_stats['games'], 1)
        home_ht_avg_goals = home_stats['ht_goals_scored'] / max(home_stats['games'], 1)
        home_home_ht_over_rate = home_stats['home_over'] / max(home_stats['home_games'], 1)
        
        away_ht_over_rate = away_stats['over_05'] / max(away_stats['games'], 1)
        away_ht_avg_goals = away_stats['ht_goals_scored'] / max(away_stats['games'], 1)
        away_away_ht_over_rate = away_stats['away_over'] / max(away_stats['away_games'], 1)
        
        # ===== FEATURES HT ULTRA-ESPEC√çFICAS =====
        
        # 1. EFICI√äNCIA HT vs FT
        if len(home_stats['ht_vs_ft_ratio']) > 0:
            home_ht_efficiency = np.mean(home_stats['ht_vs_ft_ratio'])
            home_ht_consistency = 1 / (1 + np.std(home_stats['ht_vs_ft_ratio']) + 0.01)
        else:
            home_ht_efficiency = 0.5
            home_ht_consistency = 0.5
            
        if len(away_stats['ht_vs_ft_ratio']) > 0:
            away_ht_efficiency = np.mean(away_stats['ht_vs_ft_ratio'])
            away_ht_consistency = 1 / (1 + np.std(away_stats['ht_vs_ft_ratio']) + 0.01)
        else:
            away_ht_efficiency = 0.5
            away_ht_consistency = 0.5
        
        # 2. PRESS√ÉO INICIAL E QUICK START
        home_quick_start_rate = home_stats['quick_start_games'] / max(home_stats['games'], 1)
        away_quick_start_rate = away_stats['quick_start_games'] / max(away_stats['games'], 1)
        
        home_early_aggression = home_stats['early_goals_count'] / max(home_stats['games'], 1)
        away_early_aggression = away_stats['early_goals_count'] / max(away_stats['games'], 1)
        
        # 3. MOMENTUM HT ESPEC√çFICO
        home_recent_ht = home_stats['over_list'][-5:] if len(home_stats['over_list']) >= 5 else home_stats['over_list']
        away_recent_ht = away_stats['over_list'][-5:] if len(away_stats['over_list']) >= 5 else away_stats['over_list']
        
        home_ht_momentum = sum(home_recent_ht) / len(home_recent_ht) if home_recent_ht else home_ht_over_rate
        away_ht_momentum = sum(away_recent_ht) / len(away_recent_ht) if away_recent_ht else away_ht_over_rate
        
        # 4. DOMIN√ÇNCIA E CLEAN SHEETS HT
        home_ht_clean_rate = home_stats['ht_clean_sheets'] / max(home_stats['games'], 1)
        away_ht_clean_rate = away_stats['ht_clean_sheets'] / max(away_stats['games'], 1)
        
        home_ht_dominance = home_stats['ht_dominance_games'] / max(home_stats['games'], 1)
        away_ht_dominance = away_stats['ht_dominance_games'] / max(away_stats['games'], 1)
        
        # 5. FEATURES DE LIGA HT-ESPEC√çFICAS
        league_id = row['league_id']
        league_mask = df['league_id'] == league_id
        league_ht_data = df.loc[league_mask & (df.index < idx)]
        
        if len(league_ht_data) > 0:
            league_ht_over_rate = league_ht_data['over_05'].mean()
            league_ht_avg_goals = league_ht_data['ht_total_goals'].mean()
            league_ht_volatility = league_ht_data['ht_total_goals'].std()
        else:
            league_ht_over_rate = 0.5
            league_ht_avg_goals = 0.5
            league_ht_volatility = 1.0
        
        # 6. FEATURES COMBINADAS HT-ESPEC√çFICAS
        combined_ht_strength = (home_ht_over_rate * home_ht_efficiency + away_ht_over_rate * away_ht_efficiency) / 2
        combined_ht_aggression = (home_early_aggression + away_early_aggression) / 2
        combined_ht_momentum = (home_ht_momentum + away_ht_momentum) / 2
        combined_ht_consistency = (home_ht_consistency + away_ht_consistency) / 2
        
        # 7. FEATURES AVAN√áADAS DE OPOSI√á√ÉO HT
        home_vs_clean_defense = home_ht_over_rate * (1 - away_ht_clean_rate)
        away_vs_clean_defense = away_ht_over_rate * (1 - home_ht_clean_rate)
        
        # 8. FEATURES DE TIMING E PADR√ïES HT
        if len(home_stats['ht_goals_list']) > 1:
            home_ht_variability = np.std(home_stats['ht_goals_list']) / (np.mean(home_stats['ht_goals_list']) + 0.01)
        else:
            home_ht_variability = 1.0
            
        if len(away_stats['ht_goals_list']) > 1:
            away_ht_variability = np.std(away_stats['ht_goals_list']) / (np.mean(away_stats['ht_goals_list']) + 0.01)
        else:
            away_ht_variability = 1.0
        
        # ===== CRIAR DICION√ÅRIO COM TODAS AS FEATURES HT =====
        feature_row = {
            # Features b√°sicas HT
            'home_ht_over_rate': home_ht_over_rate,
            'home_ht_avg_goals': home_ht_avg_goals,
            'home_home_ht_over_rate': home_home_ht_over_rate,
            'away_ht_over_rate': away_ht_over_rate,
            'away_ht_avg_goals': away_ht_avg_goals,
            'away_away_ht_over_rate': away_away_ht_over_rate,
            'league_ht_over_rate': league_ht_over_rate,
            'league_ht_avg_goals': league_ht_avg_goals,
            'league_ht_volatility': league_ht_volatility,
            
            # Features HT espec√≠ficas - Efici√™ncia
            'home_ht_efficiency': home_ht_efficiency,
            'away_ht_efficiency': away_ht_efficiency,
            'home_ht_consistency': home_ht_consistency,
            'away_ht_consistency': away_ht_consistency,
            'combined_ht_efficiency': (home_ht_efficiency + away_ht_efficiency) / 2,
            
            # Features HT espec√≠ficas - Agressividade inicial
            'home_quick_start_rate': home_quick_start_rate,
            'away_quick_start_rate': away_quick_start_rate,
            'home_early_aggression': home_early_aggression,
            'away_early_aggression': away_early_aggression,
            'combined_ht_aggression': combined_ht_aggression,
            
            # Features HT espec√≠ficas - Momentum
            'home_ht_momentum': home_ht_momentum,
            'away_ht_momentum': away_ht_momentum,
            'combined_ht_momentum': combined_ht_momentum,
            'ht_momentum_difference': abs(home_ht_momentum - away_ht_momentum),
            
            # Features HT espec√≠ficas - Defesa
            'home_ht_clean_rate': home_ht_clean_rate,
            'away_ht_clean_rate': away_ht_clean_rate,
            'home_ht_dominance': home_ht_dominance,
            'away_ht_dominance': away_ht_dominance,
            'home_vs_clean_defense': home_vs_clean_defense,
            'away_vs_clean_defense': away_vs_clean_defense,
            
            # Features HT espec√≠ficas - Variabilidade
            'home_ht_variability': home_ht_variability,
            'away_ht_variability': away_ht_variability,
            'combined_ht_variability': (home_ht_variability + away_ht_variability) / 2,
            
            # Features HT espec√≠ficas - For√ßa combinada
            'combined_ht_strength': combined_ht_strength,
            'combined_ht_consistency': combined_ht_consistency,
            'ht_strength_difference': abs(home_ht_over_rate - away_ht_over_rate),
            'ht_total_quality': combined_ht_strength * combined_ht_consistency,
            
            # Features HT espec√≠ficas - Contexto de liga
            'home_vs_league_ht': home_ht_over_rate - league_ht_over_rate,
            'away_vs_league_ht': away_ht_over_rate - league_ht_over_rate,
            'teams_vs_league_ht': (home_ht_over_rate + away_ht_over_rate) / 2 - league_ht_over_rate,
            
            # Features HT espec√≠ficas - Matem√°ticas avan√ßadas
            'ht_geometric_mean': np.sqrt(home_ht_over_rate * away_ht_over_rate),
            'ht_harmonic_mean': 2 / (1/(home_ht_over_rate + 0.01) + 1/(away_ht_over_rate + 0.01)),
            'ht_synergy_factor': combined_ht_strength * combined_ht_momentum * combined_ht_consistency,
            
            # Target
            'target': row['over_05']
        }
        
        features.append(feature_row)
        
        # ===== ATUALIZAR ESTAT√çSTICAS PARA PR√ìXIMA ITERA√á√ÉO =====
        ht_home_goals = row.get('ht_home_goals', 0)
        ht_away_goals = row.get('ht_away_goals', 0)
        ht_total = ht_home_goals + ht_away_goals
        
        # Atualizar home team
        team_stats[home_id]['games'] += 1
        team_stats[home_id]['over_05'] += row['over_05']
        team_stats[home_id]['ht_goals_scored'] += ht_home_goals
        team_stats[home_id]['ht_goals_conceded'] += ht_away_goals
        team_stats[home_id]['home_games'] += 1
        team_stats[home_id]['home_over'] += row['over_05']
        team_stats[home_id]['home_ht_goals'] += ht_home_goals
        team_stats[home_id]['ht_goals_list'].append(ht_home_goals)
        team_stats[home_id]['over_list'].append(row['over_05'])
        
        # Features HT espec√≠ficas para home
        if ht_away_goals == 0:
            team_stats[home_id]['ht_clean_sheets'] += 1
        if ht_home_goals > 0:
            team_stats[home_id]['quick_start_games'] += 1
        if idx < 5:  # Primeiros jogos
            team_stats[home_id]['early_goals_count'] += ht_home_goals
        if ht_home_goals > ht_away_goals:
            team_stats[home_id]['ht_dominance_games'] += 1
        
        # Adicionar ratio HT vs FT (simulado como HT efficiency)
        ht_efficiency = ht_home_goals / max(ht_total, 1) if ht_total > 0 else 0
        team_stats[home_id]['ht_vs_ft_ratio'].append(ht_efficiency)
        
        # Atualizar away team
        team_stats[away_id]['games'] += 1
        team_stats[away_id]['over_05'] += row['over_05']
        team_stats[away_id]['ht_goals_scored'] += ht_away_goals
        team_stats[away_id]['ht_goals_conceded'] += ht_home_goals
        team_stats[away_id]['away_games'] += 1
        team_stats[away_id]['away_over'] += row['over_05']
        team_stats[away_id]['away_ht_goals'] += ht_away_goals
        team_stats[away_id]['ht_goals_list'].append(ht_away_goals)
        team_stats[away_id]['over_list'].append(row['over_05'])
        
        # Features HT espec√≠ficas para away
        if ht_home_goals == 0:
            team_stats[away_id]['ht_clean_sheets'] += 1
        if ht_away_goals > 0:
            team_stats[away_id]['quick_start_games'] += 1
        if idx < 5:  # Primeiros jogos
            team_stats[away_id]['early_goals_count'] += ht_away_goals
        if ht_away_goals > ht_home_goals:
            team_stats[away_id]['ht_dominance_games'] += 1
        
        # Adicionar ratio HT vs FT (simulado como HT efficiency)
        ht_efficiency = ht_away_goals / max(ht_total, 1) if ht_total > 0 else 0
        team_stats[away_id]['ht_vs_ft_ratio'].append(ht_efficiency)
        
        # Manter apenas √∫ltimos 15 jogos para otimiza√ß√£o
        for team_id in [home_id, away_id]:
            if len(team_stats[team_id]['ht_goals_list']) > 15:
                team_stats[team_id]['ht_goals_list'] = team_stats[team_id]['ht_goals_list'][-15:]
                team_stats[team_id]['over_list'] = team_stats[team_id]['over_list'][-15:]
                team_stats[team_id]['ht_vs_ft_ratio'] = team_stats[team_id]['ht_vs_ft_ratio'][-15:]
    
    progress_bar.empty()
    features_df = pd.DataFrame(features)
    st.success(f"üéØ {len(features_df.columns)-1} features ULTRA-HT espec√≠ficas preparadas!")
    
    return features_df, team_stats

def train_maximum_performance_model(df):
    """
    üöÄ MODELO DE M√ÅXIMA PERFORMANCE PARA OVER 0.5 HT
    Todos os truques avan√ßados implementados
    """
    
    if len(df) < 200:
        st.error("‚ùå Dados insuficientes para m√°xima performance (m√≠nimo 200 jogos)")
        return None, None
    
    try:
        st.info("üéØ Iniciando treinamento M√ÅXIMA PERFORMANCE...")
        
        # 1. Preparar features ultra-espec√≠ficas HT
        features_df, team_stats = prepare_ultra_ht_features(df)
        
        feature_cols = [col for col in features_df.columns if col != 'target']
        X = features_df[feature_cols]
        y = features_df['target']
        
        st.info(f"üéØ {len(feature_cols)} features ULTRA-HT espec√≠ficas")
        
        # 2. VALIDA√á√ÉO TEMPORAL (n√£o aleat√≥ria)
        st.info("‚è±Ô∏è Aplicando valida√ß√£o temporal...")
        
        # Split temporal: 70% mais antigo treino, 15% valida√ß√£o, 15% mais recente teste
        n_samples = len(X)
        train_end = int(n_samples * 0.70)
        val_end = int(n_samples * 0.85)
        
        X_train = X.iloc[:train_end]
        y_train = y.iloc[:train_end]
        X_val = X.iloc[train_end:val_end]
        y_val = y.iloc[train_end:val_end]
        X_test = X.iloc[val_end:]
        y_test = y.iloc[val_end:]
        
        st.info(f"üìä Split temporal: {len(X_train)} treino, {len(X_val)} valida√ß√£o, {len(X_test)} teste")
        
        # 3. BALANCEAMENTO DE CLASSES COM SMOTEENN
        st.info("‚öñÔ∏è Aplicando balanceamento avan√ßado (SMOTEENN)...")
        
        try:
            smoteenn = SMOTEENN(random_state=42)
            X_train_balanced, y_train_balanced = smoteenn.fit_resample(X_train, y_train)
            st.success(f"‚úÖ Balanceamento: {len(X_train)} ‚Üí {len(X_train_balanced)} amostras")
        except:
            # Fallback para SMOTE simples
            smote = SMOTE(random_state=42)
            X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)
            st.info(f"üìä SMOTE aplicado: {len(X_train)} ‚Üí {len(X_train_balanced)} amostras")
        
        # 4. PADRONIZA√á√ÉO
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train_balanced)
        X_val_scaled = scaler.transform(X_val)
        X_test_scaled = scaler.transform(X_test)
        
        # 5. ENSEMBLE M√ÅXIMA PERFORMANCE
        st.info("üöÄ Treinando ensemble de m√°xima performance...")
        
        models = {}
        
        # RandomForest otimizado
        models['RandomForest'] = RandomForestClassifier(
            n_estimators=500,      # Mais √°rvores
            max_depth=15,          # Mais profundo
            min_samples_split=2,   # Mais flex√≠vel
            min_samples_leaf=1,    # Mais flex√≠vel
            max_features='sqrt',   # Otimizado
            bootstrap=True,
            oob_score=True,
            random_state=42,
            n_jobs=-1
        )
        
        # GradientBoosting otimizado
        models['GradientBoosting'] = GradientBoostingClassifier(
            n_estimators=500,      # Mais estimadores
            learning_rate=0.05,    # Learning rate menor
            max_depth=8,           # Mais profundo
            min_samples_split=2,   # Mais flex√≠vel
            min_samples_leaf=1,    # Mais flex√≠vel
            subsample=0.8,         # Regulariza√ß√£o
            random_state=42
        )
        
        # LightGBM se dispon√≠vel
        if LIGHTGBM_AVAILABLE:
            models['LightGBM'] = lgb.LGBMClassifier(
                n_estimators=500,
                learning_rate=0.05,
                max_depth=10,
                num_leaves=100,
                min_child_samples=5,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                verbose=-1
            )
        
        # XGBoost se dispon√≠vel  
        if XGBOOST_AVAILABLE:
            models['XGBoost'] = xgb.XGBClassifier(
                n_estimators=500,
                learning_rate=0.05,
                max_depth=8,
                min_child_weight=1,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                eval_metric='logloss'
            )
        
        # 6. TREINAR E AVALIAR TODOS OS MODELOS
        results = {}
        trained_models = {}
        
        for name, model in models.items():
            with st.spinner(f"Treinando {name}..."):
                model.fit(X_train_scaled, y_train_balanced)
                trained_models[name] = model
                
                # Valida√ß√£o
                val_pred = model.predict(X_val_scaled)
                val_proba = model.predict_proba(X_val_scaled)[:, 1]
                
                # Teste
                test_pred = model.predict(X_test_scaled)
                test_proba = model.predict_proba(X_test_scaled)[:, 1]
                
                # M√©tricas completas
                results[name] = {
                    'val_accuracy': accuracy_score(y_val, val_pred),
                    'val_auc': roc_auc_score(y_val, val_proba),
                    'test_accuracy': accuracy_score(y_test, test_pred),
                    'test_precision': precision_score(y_test, test_pred),
                    'test_recall': recall_score(y_test, test_pred),
                    'test_f1': f1_score(y_test, test_pred),
                    'test_auc': roc_auc_score(y_test, test_proba)
                }
                
                st.success(f"‚úÖ {name}: Acur√°cia={results[name]['test_accuracy']:.3f} | AUC={results[name]['test_auc']:.3f}")
        
        # 7. VOTING CLASSIFIER COM OS MELHORES
        st.info("üèÜ Criando ensemble final com voting...")
        
        # Selecionar top 3 modelos por AUC
        top_models = sorted(results.items(), key=lambda x: x[1]['test_auc'], reverse=True)[:3]
        
        voting_estimators = []
        for model_name, _ in top_models:
            voting_estimators.append((model_name, trained_models[model_name]))
        
        # Voting Classifier
        voting_model = VotingClassifier(
            estimators=voting_estimators,
            voting='soft'  # Usar probabilidades
        )
        
        voting_model.fit(X_train_scaled, y_train_balanced)
        
        # Avaliar ensemble final
        final_val_pred = voting_model.predict(X_val_scaled)
        final_test_pred = voting_model.predict(X_test_scaled)
        final_test_proba = voting_model.predict_proba(X_test_scaled)[:, 1]
        
        final_results = {
            'val_accuracy': accuracy_score(y_val, final_val_pred),
            'test_accuracy': accuracy_score(y_test, final_test_pred),
            'test_precision': precision_score(y_test, final_test_pred),
            'test_recall': recall_score(y_test, final_test_pred),
            'test_f1': f1_score(y_test, final_test_pred),
            'test_auc': roc_auc_score(y_test, final_test_proba)
        }
        
        results['VotingEnsemble'] = final_results
        
        st.success(f"üèÜ ENSEMBLE FINAL: Acur√°cia={final_results['test_accuracy']:.1%} | F1={final_results['test_f1']:.1%} | AUC={final_results['test_auc']:.3f}")
        
        # 8. ESCOLHER MELHOR MODELO
        best_model_name = max(results.items(), key=lambda x: x[1]['test_f1'])[0]
        
        if best_model_name == 'VotingEnsemble':
            best_model = voting_model
        else:
            best_model = trained_models[best_model_name]
        
        # 9. SALVAR MODELO COMPLETO
        model_data = {
            'model': best_model,
            'scaler': scaler,
            'feature_cols': feature_cols,
            'team_stats': team_stats,
            'results': results,
            'best_model_name': best_model_name,
            'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'total_samples': len(df),
            'features_count': len(feature_cols),
            'ultra_ht_features': True,
            'temporal_validation': True,
            'balanced_training': True,
            'ensemble_model': True
        }
        
        # Salvar
        try:
            model_path = os.path.join(MODEL_DIR, f"ultra_ht_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl")
            joblib.dump(model_data, model_path)
            st.success(f"üíæ Modelo salvo: {model_path}")
        except Exception:
            pass
        
        st.session_state.trained_model = model_data
        st.session_state.model_trained = True
        
        return model_data, results
        
    except Exception as e:
        st.error(f"‚ùå Erro no treinamento: {str(e)}")
        return None, None

def predict_matches_ultra(fixtures, model_data):
    """Previs√µes com modelo de m√°xima performance"""
    predictions = []
    
    if not model_data:
        return predictions
    
    model = model_data['model']
    scaler = model_data['scaler']
    feature_cols = model_data['feature_cols']
    team_stats = model_data['team_stats']
    
    for fixture in fixtures:
        if fixture['fixture']['status']['short'] not in ['NS', 'TBD']:
            continue
        
        try:
            home_id = fixture['teams']['home']['id']
            away_id = fixture['teams']['away']['id']
            
            if home_id not in team_stats or away_id not in team_stats:
                continue
            
            home_stats = team_stats[home_id]
            away_stats = team_stats[away_id]
            
            # Calcular todas as features HT-espec√≠ficas
            features = {}
            
            # Features b√°sicas
            features['home_ht_over_rate'] = home_stats['over_05'] / max(home_stats['games'], 1)
            features['away_ht_over_rate'] = away_stats['over_05'] / max(away_stats['games'], 1)
            features['home_ht_avg_goals'] = home_stats['ht_goals_scored'] / max(home_stats['games'], 1)
            features['away_ht_avg_goals'] = away_stats['ht_goals_scored'] / max(away_stats['games'], 1)
            
            # Features avan√ßadas (simplificadas para previs√£o)
            for col in feature_cols:
                if col not in features:
                    if 'home' in col and 'ht' in col:
                        features[col] = features.get('home_ht_over_rate', 0.5)
                    elif 'away' in col and 'ht' in col:
                        features[col] = features.get('away_ht_over_rate', 0.5)
                    elif 'combined' in col:
                        features[col] = (features.get('home_ht_over_rate', 0.5) + features.get('away_ht_over_rate', 0.5)) / 2
                    elif 'league' in col:
                        features[col] = 0.5
                    else:
                        features[col] = 0.5
            
            # Fazer previs√£o
            X = pd.DataFrame([features])[feature_cols]
            X_scaled = scaler.transform(X)
            
            pred_proba = model.predict_proba(X_scaled)[0]
            pred_class = model.predict(X_scaled)[0]
            confidence = max(pred_proba) * 100
            
            prediction = {
                'home_team': fixture['teams']['home']['name'],
                'away_team': fixture['teams']['away']['name'],
                'league': fixture['league']['name'],
                'country': fixture['league']['country'],
                'kickoff': fixture['fixture']['date'],
                'prediction': 'OVER 0.5' if pred_class == 1 else 'UNDER 0.5',
                'confidence': confidence,
                'probability_over': pred_proba[1] * 100,
                'probability_under': pred_proba[0] * 100,
                'ultra_model': True
            }
            
            predictions.append(prediction)
            
        except Exception:
            continue
    
    predictions.sort(key=lambda x: x['confidence'], reverse=True)
    return predictions

def display_ultra_prediction_card(pred):
    """Card otimizado para m√°xima performance"""
    with st.container():
        col1, col2 = st.columns([4, 1])
        
        with col1:
            st.subheader(f"‚öΩ {pred['home_team']} vs {pred['away_team']}")
        
        with col2:
            if pred['confidence'] > 85:
                st.success(f"**{pred['confidence']:.1f}%**")
            elif pred['confidence'] > 75:
                st.info(f"**{pred['confidence']:.1f}%**")
            else:
                st.warning(f"**{pred['confidence']:.1f}%**")
        
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"üèÜ **Liga:** {pred['league']} ({pred['country']})")
        with col2:
            try:
                hora = pred['kickoff'][11:16]
                st.write(f"üïê **Hor√°rio:** {hora}")
            except:
                st.write(f"üïê **Hor√°rio:** --:--")
        
        if pred['prediction'] == 'OVER 0.5':
            st.success(f"üéØ **{pred['prediction']}** - Modelo Ultra-HT")
        else:
            st.info(f"üéØ **{pred['prediction']}** - Modelo Ultra-HT")
        
        st.markdown("---")

def main():
    st.title("‚öΩ HT Goals AI Engine - M√ÅXIMA PERFORMANCE")
    st.markdown("üéØ **Sistema Ultra-Otimizado para Over 0.5 HT - Taxa de Acerto M√°xima**")
    
    # Teste de conectividade
    conn_ok, conn_msg = test_api_connection()
    
    with st.sidebar:
        st.title("üéØ ULTRA PERFORMANCE")
        
        if conn_ok:
            st.success("‚úÖ API conectada")
        else:
            st.error(f"‚ùå {conn_msg}")
        
        st.subheader("üöÄ Configura√ß√µes M√°xima Performance")
        
        days_training = st.slider(
            "üìä Dias para treinamento:",
            min_value=30,
            max_value=365,
            value=120,
            help="Mais dados = maior precis√£o"
        )
        
        use_cache = st.checkbox(
            "üíæ Usar dados em cache",
            value=True,
            help="Recomendado para velocidade"
        )
        
        st.subheader("üéØ Features Ultra-HT")
        st.success("""
        ‚úÖ **40+ Features HT-Espec√≠ficas**
        ‚úÖ **Valida√ß√£o Temporal**
        ‚úÖ **Balanceamento SMOTEENN**
        ‚úÖ **Ensemble Voting**
        ‚úÖ **LightGBM + XGBoost**
        ‚úÖ **Otimiza√ß√£o Completa**
        """)
        
        # Status do modelo
        if st.session_state.model_trained and st.session_state.trained_model:
            model_data = st.session_state.trained_model
            st.success("‚úÖ Modelo Ultra-HT ativo")
            st.info(f"üìÖ Treinado: {model_data['training_date']}")
            st.info(f"üéØ Features: {model_data['features_count']}")
            
            if 'results' in model_data:
                best_result = max(model_data['results'].items(), key=lambda x: x[1]['test_f1'])
                st.success(f"üèÜ {best_result[0]}")
                st.success(f"üìà Acur√°cia: {best_result[1]['test_accuracy']:.1%}")
                st.success(f"üéØ F1-Score: {best_result[1]['test_f1']:.1%}")
        else:
            st.warning("‚ö†Ô∏è Modelo n√£o treinado")
    
    # Tabs simplificadas para m√°xima performance
    tab1, tab2 = st.tabs(["üéØ Previs√µes Ultra-HT", "üöÄ Treinar Modelo M√°xima Performance"])
    
    with tab1:
        st.header("üéØ Previs√µes Over 0.5 HT - M√°xima Performance")
        
        if not st.session_state.get('model_trained', False):
            st.warning("‚ö†Ô∏è **Treine o modelo de m√°xima performance primeiro!**")
            st.info("üëà V√° para a aba 'Treinar Modelo M√°xima Performance'")
        else:
            model_data = st.session_state.trained_model
            
            selected_date = st.date_input(
                "üìÖ Data para an√°lise:",
                value=datetime.now().date()
            )
            
            date_str = selected_date.strftime('%Y-%m-%d')
            
            with st.spinner("üîç Buscando jogos..."):
                fixtures = get_fixtures_cached(date_str)
            
            if not fixtures:
                st.info(f"üìÖ Nenhum jogo encontrado para {selected_date.strftime('%d/%m/%Y')}")
            else:
                with st.spinner("üéØ Aplicando modelo Ultra-HT..."):
                    predictions = predict_matches_ultra(fixtures, model_data)
                
                if predictions:
                    # Estat√≠sticas
                    total_games = len(predictions)
                    over_predictions = len([p for p in predictions if p['prediction'] == 'OVER 0.5'])
                    high_confidence = len([p for p in predictions if p['confidence'] > 80])
                    ultra_high = len([p for p in predictions if p['confidence'] > 90])
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("üéÆ Total Jogos", total_games)
                    with col2:
                        st.metric("üìà Over 0.5", over_predictions)
                    with col3:
                        st.metric("üéØ Confian√ßa >80%", high_confidence)
                    with col4:
                        st.metric("üöÄ Confian√ßa >90%", ultra_high)
                    
                    # Melhores apostas
                    best_bets = [p for p in predictions if p['prediction'] == 'OVER 0.5' and p['confidence'] > 70]
                    
                    if best_bets:
                        st.subheader("üèÜ Apostas Ultra-HT Recomendadas")
                        
                        for pred in best_bets[:8]:
                            display_ultra_prediction_card(pred)
                    else:
                        st.info("ü§∑ Nenhuma aposta Over 0.5 com alta confian√ßa hoje")
                    
                    # Tabela completa
                    st.subheader("üìã Todas as Previs√µes")
                    
                    table_data = []
                    for pred in predictions:
                        try:
                            hora = pred['kickoff'][11:16]
                        except:
                            hora = "--:--"
                        
                        table_data.append({
                            'Hora': hora,
                            'Jogo': f"{pred['home_team']} vs {pred['away_team']}",
                            'Liga': pred['league'],
                            'Previs√£o': pred['prediction'],
                            'Confian√ßa': f"{pred['confidence']:.0f}%"
                        })
                    
                    df_table = pd.DataFrame(table_data)
                    st.dataframe(df_table, use_container_width=True, hide_index=True)
                else:
                    st.info("ü§∑ Nenhuma previs√£o dispon√≠vel")
    
    with tab2:
        st.header("üöÄ Treinar Modelo de M√°xima Performance")
        
        st.success("""
        üéØ **SISTEMA DE M√ÅXIMA PERFORMANCE PARA OVER 0.5 HT:**
        
        **üî¨ Features Ultra-Espec√≠ficas (40+):**
        - ‚úÖ Efici√™ncia HT vs FT
        - ‚úÖ Quick Start Rate
        - ‚úÖ Early Aggression Index  
        - ‚úÖ HT Momentum Espec√≠fico
        - ‚úÖ Clean Sheets HT
        - ‚úÖ Domin√¢ncia HT
        - ‚úÖ Variabilidade HT
        - ‚úÖ Synergy Factor
        
        **üß† T√©cnicas Avan√ßadas:**
        - ‚úÖ Valida√ß√£o Temporal (n√£o aleat√≥ria)
        - ‚úÖ Balanceamento SMOTEENN
        - ‚úÖ Ensemble Voting Classifier
        - ‚úÖ LightGBM + XGBoost + RF + GB
        - ‚úÖ Otimiza√ß√£o de hiperpar√¢metros
        """)
        
        if not conn_ok:
            st.error(f"‚ùå {conn_msg}")
            st.info("üí° Marque 'Usar dados em cache'")
        
        st.info(f"""
        **Configura√ß√£o do treinamento:**
        - üéØ **{days_training} dias** de dados hist√≥ricos
        - üß† **40+ features** ultra-espec√≠ficas HT
        - ‚è±Ô∏è **Valida√ß√£o temporal** (70% treino, 15% val, 15% teste)
        - ‚öñÔ∏è **Balanceamento** autom√°tico de classes
        - üèÜ **Ensemble** com 4+ algoritmos
        """)
        
        if st.button("üöÄ TREINAR MODELO M√ÅXIMA PERFORMANCE", type="primary", use_container_width=True):
            with st.spinner(f"üìä Coletando {days_training} dias de dados..."):
                df = collect_historical_data_smart(days=days_training, use_cached=use_cache)
            
            if df.empty:
                st.error("‚ùå N√£o foi poss√≠vel coletar dados suficientes")
                st.info("üí° Solu√ß√µes:")
                st.info("- Marque 'Usar dados em cache'")
                st.info("- Verifique conex√£o internet")
            else:
                st.success(f"‚úÖ {len(df)} jogos coletados")
                
                model_data, results = train_maximum_performance_model(df)
                
                if model_data and results:
                    st.balloons()
                    st.success("üéâ MODELO DE M√ÅXIMA PERFORMANCE TREINADO!")
                    
                    # Mostrar resultados
                    st.subheader("üèÜ Resultados do Modelo Ultra-HT")
                    
                    best_model = max(results.items(), key=lambda x: x[1]['test_f1'])
                    
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("üéØ Acur√°cia", f"{best_model[1]['test_accuracy']:.1%}")
                    with col2:
                        st.metric("üíé Precis√£o", f"{best_model[1]['test_precision']:.1%}")
                    with col3:
                        st.metric("üìä Recall", f"{best_model[1]['test_recall']:.1%}")
                    with col4:
                        st.metric("üèÖ F1-Score", f"{best_model[1]['test_f1']:.1%}")
                    
                    # Compara√ß√£o de modelos
                    st.subheader("üìà Compara√ß√£o de Algoritmos")
                    
                    results_table = []
                    for model_name, metrics in results.items():
                        results_table.append({
                            'Modelo': model_name,
                            'Acur√°cia': f"{metrics['test_accuracy']:.1%}",
                            'Precis√£o': f"{metrics['test_precision']:.1%}",
                            'Recall': f"{metrics['test_recall']:.1%}",
                            'F1-Score': f"{metrics['test_f1']:.1%}",
                            'AUC': f"{metrics.get('test_auc', 0):.3f}"
                        })
                    
                    results_df = pd.DataFrame(results_table)
                    st.dataframe(results_df, use_container_width=True, hide_index=True)
                    
                    st.success(f"üèÜ **Melhor modelo:** {best_model[0]} com F1-Score de {best_model[1]['test_f1']:.1%}")
                    
                    if model_data.get('ultra_ht_features'):
                        st.success("üéØ **Features Ultra-HT ativas!**")
                    if model_data.get('temporal_validation'):
                        st.success("‚è±Ô∏è **Valida√ß√£o temporal aplicada!**")
                    if model_data.get('balanced_training'):
                        st.success("‚öñÔ∏è **Balanceamento de classes ativo!**")
                    if model_data.get('ensemble_model'):
                        st.success("üèÜ **Ensemble modelo ativo!**")
                        
                else:
                    st.error("‚ùå Falha no treinamento")

if __name__ == "__main__":
    main()
